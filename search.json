[
  {
    "objectID": "notebooks/local_generator.html",
    "href": "notebooks/local_generator.html",
    "title": "Local Generator",
    "section": "",
    "text": "To make it more “understandable” where material is placed we generate a slowly varying landscape by interpolation of a low resolution map.\n\ndef generate_heatmap(features = 8, zoom = 16):\n  heatmap = np.random.random((features,features))-0.5\n  large_heatmap = scipy.ndimage.zoom(heatmap, zoom)\n  return large_heatmap\n\nlarge_heatmap = generate_heatmap()\nplt.imshow(large_heatmap)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()"
  },
  {
    "objectID": "notebooks/local_generator.html#generating-the-brush",
    "href": "notebooks/local_generator.html#generating-the-brush",
    "title": "Local Generator",
    "section": "Generating the brush",
    "text": "Generating the brush\n\ndef circular_brush(diameter):\n    radius = diameter / 2\n    X, Y = np.mgrid[-radius : radius : 1j * diameter, -radius : radius : 1j * diameter]\n    _int = lambda x: np.array(x, dtype=int)\n    brush = _int(X) ** 2 + _int(Y) ** 2 < radius ** 2\n    return brush\n\n\nkernel_size=9\nbrush = np.ones((kernel_size, kernel_size))\nbrush[0,0] = 0\nbrush[0,-1] = 0\nbrush[-1,0] = 0\nbrush[-1,-1] = 0\n\nbrush = circular_brush(kernel_size)\nbrush = brush.astype(bool)\n\ndef show_brush(brush):\n  nx, ny = brush.shape\n  plt.imshow(brush)\n  ax = plt.gca()\n  ax.set_yticks(np.arange(nx)+0.5)\n  ax.set_yticklabels([\"\" for i in range(nx)])\n  ax.set_xticks(np.arange(ny)+0.5)\n  ax.set_xticklabels([\"\" for i in range(ny)])\n  ax.set_yticks(np.arange(nx), minor=True)\n  ax.set_yticklabels([f\"{i}\" for i in range(nx)], minor=True)\n  ax.set_xticks(np.arange(ny), minor=True)\n  ax.set_xticklabels([f\"{i}\" for i in range(ny)], minor=True)\n  plt.grid()\n\nshow_brush(brush)\n\n\n\n\n\nconv_brush = scipy.ndimage.binary_dilation(np.pad(brush, len(brush)//2), brush)\nshow_brush(conv_brush)\nplt.colorbar()\n\nplt.figure()\ndouble_conv_brush = scipy.ndimage.binary_dilation(np.pad(conv_brush, len(brush)//2), brush)\nshow_brush(double_conv_brush)\nplt.colorbar()\n\n<matplotlib.colorbar.Colorbar at 0x7fa09c5c77f0>"
  },
  {
    "objectID": "notebooks/local_generator.html#running-the-generator",
    "href": "notebooks/local_generator.html#running-the-generator",
    "title": "Local Generator",
    "section": "Running the Generator",
    "text": "Running the Generator\n\nsource\n\ndilate\n\n dilate (img, brush, count_time=True)\n\n\nsource\n\n\nTimes\n\n Times (update:float=0, dilate:float=0, required:float=0,\n        resolving:float=0, select:float=0, convolute:float=0,\n        existing:float=0, impossible:float=0, possible:float=0,\n        valid:float=0, free:float=0, local_required:float=0,\n        local_resolving:float=0, local_dilate:float=0)\n\n\nsource\n\n\nGeneratorState\n\n GeneratorState (heatmap, brush)\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nlog\n\n log (*args, level=1)\n\n\ndef compare(s_try, s_actual, v_try, v_actual, name):\n  \"\"\"\n  Compares properties of a new implementation and the original slow one.\n  Raises Error if they are not equal and plots the comparison\n  \"\"\"\n  compare_s = np.logical_xor(s_try,s_actual)\n  compare_v = np.logical_xor(v_try,v_actual)\n\n  if compare_s.any() or compare_v.any():\n    plt.figure(figsize = (6,9))\n    plt.subplot(321)\n    plt.title(\"Compare Solid\")\n    plt.imshow(compare_s, vmax=1, vmin=0)\n    plt.subplot(322)\n    plt.title(\"Compare Void\")\n    plt.imshow(compare_v, vmax=1, vmin=0)\n    plt.subplot(323)\n    plt.title(f\"{name} Solid\")\n    plt.imshow(s_try, vmax=1, vmin=0)\n    plt.subplot(324)\n    plt.title(f\"{name} Void\")\n    plt.imshow(v_try, vmax=1, vmin=0)\n    plt.subplot(325)\n    plt.title(f\"Actual {name} Solid\")\n    plt.imshow(s_actual, vmax=1, vmin=0)\n    plt.subplot(326)\n    plt.title(f\"Actual {name} Void\")\n    plt.imshow(v_actual, vmax=1, vmin=0)\n    plt.show()\n    raise ValueError(f\"Calculation of {name} wrong\")\n\ndef check_valid(state: GeneratorState):\n  if debug>2:\n    times.possible -= time.process_time() \n    p_s_possible_real = possible_pixels(state.t_s_valid,state.t_s,brush)\n    p_v_possible_real = possible_pixels(state.t_v_valid,state.t_v,brush)\n    times.possible += time.process_time() \n    compare(state.p_s_possible,p_s_possible_real, state.p_v_possible,p_v_possible_real, \"possible\")\n\n  if debug>2:\n    p_s_possible_dilated_real = dilate(state.p_s_possible, state.brush, False)\n    p_v_possible_dilated_real = dilate(state.p_v_possible, state.brush, False)\n    compare(state.dilated_p_s_possible,p_s_possible_dilated_real, state.dilated_p_v_possible,p_v_possible_dilated_real, \"dilated possible\")\n\n    t_s_free_real = free_touches(state.p_v_possible, state.t_s_valid, state.brush)\n    t_v_free_real = free_touches(state.p_s_possible, state.t_v_valid, state.brush)\n    compare(state.t_s_free,t_s_free_real, state.t_v_free,t_v_free_real, \"free\")\n\n  if debug>1:\n    t_s_valid_real = valid_touches(state.t_s_impossible, state.t_s)\n    t_v_valid_real = valid_touches(state.t_v_impossible, state.t_v)\n    compare(state.t_s_valid, t_s_valid_real, state.t_v_valid, t_v_valid_real, \"valid\")\n\n  if state.t_s_free.any() or state.t_v_free.any():\n    return\n\n  if debug>1:\n    p_s_required_real = required_pixels(state.p_s_existing, state.p_v_possible)\n    p_v_required_real = required_pixels(state.p_v_existing, state.p_s_possible)\n    compare(state.p_s_required,p_s_required_real, state.p_v_required,p_v_required_real, \"required\")\n  \n  if debug>1:\n    p_s_required_dilated_real = dilate(state.p_s_required, state.brush)\n    p_v_required_dilated_real = dilate(state.p_v_required, state.brush)\n    compare(state.dilated_p_s_required, p_s_required_dilated_real, state.dilated_p_v_required, p_v_required_dilated_real, \"dilated required\")\n\n    t_s_resolving_real = resolving_touches(state.p_s_required, state.t_s_valid, state.brush)\n    t_v_resolving_real = resolving_touches(state.p_v_required, state.t_v_valid, state.brush)\n    compare(state.t_s_resolving,t_s_resolving_real, state.t_v_resolving,t_v_resolving_real, \"resolving\")\n\n\nsource\n\n\ngenerate\n\n generate (heatmap, brush, t_s:numpy.ndarray=None, t_v:numpy.ndarray=None)\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nheatmap\n\n\nthe latent space representation\n\n\nbrush\n\n\nthe brush, determining the fabrication constraints\n\n\nt_s\nndarray\nNone\ninitial touches for the solid\n\n\nt_v\nndarray\nNone\ninitial touches for the void\n\n\n\n\nsource\n\n\nforce_update\n\n force_update (state)\n\n\nsource\n\n\nupdate_resolving\n\n update_resolving (state)\n\n\nsource\n\n\ntrack\n\n track (img, pos, brush, invert=False)\n\n\nsource\n\n\nlocal_dilate\n\n local_dilate (img, pos, brush, res, l=None, grow=True, plot=False,\n               plot_name='')\n\n\nsource\n\n\ntouch\n\n touch (flat_index:int, state:__main__.GeneratorState, solid:bool,\n        track_possible:bool=True)\n\nPerform a touch on the given index of the flattened map and track the consequences\n\nsource\n\n\nselect_single\n\n select_single (s_valid, v_valid, state)\n\n\nsource\n\n\ngenerate_feasible_design\n\n generate_feasible_design (latent_t, brush, init_touches_solid=None,\n                           init_touches_void=None, verbose=False)\n\n\nsource\n\n\ngenerate_feasible_design_mask\n\n generate_feasible_design_mask (latent_t, brush, init_touches_solid=None,\n                                init_touches_void=None, verbose=False)\n\n\nsource\n\n\ngenerate_feasible_design_mask_jvp\n\n generate_feasible_design_mask_jvp (primals, tangents)\n\n\ntimes = Times()\ndebug=0\ngenerate(large_heatmap, brush)\n\n<__main__.GeneratorState at 0x7fa08ccfd3d0>\n\n\n\n\nTimes for 128 sidelength\nNo tracking: 6.94s\nWith partial tracking of existing: 6.09s\nWith full tracking of existing: 5.72s\nWith tracking of existing, impossible touches and possible pixels: 3.77s\n\ntimes.__dict__\n\n{'update': 0.9670974000000028,\n 'dilate': 0.9226746999999982,\n 'required': 0.004335000000005529,\n 'resolving': 0.9273703000000051,\n 'select': 2.1701427000000035,\n 'convolute': 1.2666136000000074,\n 'existing': 0.1988380999999988,\n 'impossible': 0,\n 'possible': 0,\n 'valid': 0.01137620000000883,\n 'free': 0.08332150000000382,\n 'local_required': 0.005919800000003583,\n 'local_resolving': 0.3748742000000034,\n 'local_dilate': 0.5014807000000232}\n\n\n\nimport pandas as pd\nimport numpy as np\nfrom tqdm.notebook import tqdm\n\ndebug=0 df = [] for features in tqdm([2, 4, 8, 10, 12, 13, 14, 15, 16, 17, 18], desc=“features”, position=0):\nfor i in tqdm(range(50//features), desc=“iteration”, position=1, leave=False): heatmap = generate_heatmap(features, zoom=16) times = Times() generate(heatmap) dic = times.__dict__ dic[“features”] = features df.append(dic)\ndf = pd.DataFrame(df)\n\n#df.to_pickle(\"timing.pkl\")\n\n\ndf = pd.read_pickle(\"../resources/timing.pkl\")\n\n\ndf[\"pixels\"] = df[\"features\"]**2*16**2\ndf[\"total\"] = df[\"update\"]+df[\"select\"]\nlinear = [\"local_dilate\", \"local_required\", \"local_resolving\", \"existing\", \"impossible\", \"possible\", \"valid\", \"free\"]\ndf[\"linear_ops\"] = df[linear].sum(axis=\"columns\")\nexclude = [\"features\", \"required\", \"update+select\", \"features_sq\", \"update\", \"select\"]\ndf = df.drop(columns=exclude)\n\nt_mean = df.groupby(\"pixels\").agg(np.mean)\nt_std = df.groupby(\"pixels\").agg(np.std)\n\n\ndef plot_timing(t_mean, t_std):\n  for ((col_mean,val_mean), (col_std, val_std)) in zip(t_mean.items(), t_std.items()):\n      plt.errorbar(val_mean.index, val_mean, val_std*2, label=col_mean)\n      #t_mean.drop(columns=linear).plot(y=\"mean\", yerr=\"std\")\n      plt.ylabel(\"Time [s]\")\n      plt.xlabel(\"Number Pixels\")\n\n\nplt.figure(constrained_layout=True)\nplot_timing(t_mean.drop(columns=linear), t_std.drop(columns=linear))\nplt.legend()\nplt.savefig(\"total_time.png\")\n\n\n\n\n\nplt.figure(constrained_layout=True)\nplot_timing(t_mean[linear], t_std[linear])\nplt.legend()\nplt.savefig(\"linear_time.png\")"
  },
  {
    "objectID": "notebooks/inverse_design.html",
    "href": "notebooks/inverse_design.html",
    "title": "Inverse Design",
    "section": "",
    "text": "This notebook was adapted from Ceviche’s inverse design introduction to use a JAX-based optimization loop in stead of the default Ceviche optimization loop."
  },
  {
    "objectID": "notebooks/inverse_design.html#parameters",
    "href": "notebooks/inverse_design.html#parameters",
    "title": "Inverse Design",
    "section": "Parameters",
    "text": "Parameters\nOur toy optimization problem will be to design a device that converts an input in the first-order mode into an output as the second-order mode. First, we define the parameters of our device and optimization:\n\n# Angular frequency of the source in Hz\nomega = 2 * np.pi * 200e12\n# Spatial resolution in meters\ndl = 40e-9\n# Number of pixels in x-direction\nNx = 100\n# Number of pixels in y-direction\nNy = 100\n# Number of pixels in the PMLs in each direction\nNpml = 20\n# Initial value of the structure's relative permittivity\nepsr_init = 12.0\n# Space between the PMLs and the design region (in pixels)\nspace = 10\n# Width of the waveguide (in pixels)\nwg_width = 12\n# Length in pixels of the source/probe slices on each side of the center point\nspace_slice = 8\n# Number of epochs in the optimization\nNsteps = 100\n# Step size for the Adam optimizer\nstep_size = 1e-2"
  },
  {
    "objectID": "notebooks/inverse_design.html#brush",
    "href": "notebooks/inverse_design.html#brush",
    "title": "Inverse Design",
    "section": "Brush",
    "text": "Brush\n\nbrush = notched_square_brush(5, 1)\nshow_mask(brush)\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)"
  },
  {
    "objectID": "notebooks/inverse_design.html#initial-device",
    "href": "notebooks/inverse_design.html#initial-device",
    "title": "Inverse Design",
    "section": "Initial Device",
    "text": "Initial Device\n\n# Initialize the parametrization rho and the design region\nepsr, bg_epsr, design_region, input_slice, output_slice = init_domain(\n    Nx, Ny, Npml, space=space, wg_width=wg_width, space_slice=space_slice\n)\n\nepsr_total = mask_combine_epsr(epsr, bg_epsr, design_region)\n\n# Setup source\nsource = insert_mode(omega, dl, input_slice.x, input_slice.y, epsr_total, m=1)\n\n# Setup probe\nprobe = insert_mode(omega, dl, output_slice.x, output_slice.y, epsr_total, m=2)\n\n\n# Simulate initial device\nsimulation, ax = viz_sim(epsr_total, source, slices=[input_slice, output_slice])\n\n# get normalization factor (field overlap before optimizing)\n_, _, Ez = simulation.solve(source)\nE0 = mode_overlap(Ez, probe)\n\n\n\n\n\nsource\n\nget_design_region\n\n get_design_region (epsr, design_region=array([[0., 0., 0., ..., 0., 0.,\n                    0.],        [0., 0., 0., ..., 0., 0., 0.],        [0.,\n                    0., 0., ..., 0., 0., 0.],        ...,        [0., 0.,\n                    0., ..., 0., 0., 0.],        [0., 0., 0., ..., 0., 0.,\n                    0.],        [0., 0., 0., ..., 0., 0., 0.]]))\n\n\nsource\n\n\nset_design_region\n\n set_design_region (epsr, value, design_region=array([[0., 0., 0., ...,\n                    0., 0., 0.],        [0., 0., 0., ..., 0., 0., 0.],\n                    [0., 0., 0., ..., 0., 0., 0.],        ...,        [0.,\n                    0., 0., ..., 0., 0., 0.],        [0., 0., 0., ..., 0.,\n                    0., 0.],        [0., 0., 0., ..., 0., 0., 0.]]))"
  },
  {
    "objectID": "notebooks/inverse_design.html#latent-weights",
    "href": "notebooks/inverse_design.html#latent-weights",
    "title": "Inverse Design",
    "section": "Latent Weights",
    "text": "Latent Weights\n\n#latent = get_design_region(new_latent_design((Nx, Ny), r=0))\nlatent = new_latent_design((Nx, Ny), r=0)\nlatent_t = transform(latent, brush)\nplt.imshow(get_design_region(latent_t), cmap=\"Greys\", vmin=-1, vmax=1)\nplt.colorbar()\nplt.show()"
  },
  {
    "objectID": "notebooks/inverse_design.html#forward-pass",
    "href": "notebooks/inverse_design.html#forward-pass",
    "title": "Inverse Design",
    "section": "Forward Pass",
    "text": "Forward Pass\n\ndesign = generate_feasible_design(latent_t, brush, verbose=False)\n\n\nmask = generate_feasible_design_mask(latent_t, brush)\n\n\nfull_mask = np.zeros_like(epsr, dtype=bool)\n#full_mask = set_design_region(full_mask, mask)\n\nplt.imshow(mask, cmap=\"Greys\")\nplt.colorbar()\nplt.show()\n\nplt.imshow(full_mask, cmap=\"Greys\")\nplt.colorbar()\nplt.show()\n\nCPU times: user 143 ms, sys: 0 ns, total: 143 ms\nWall time: 297 ms\n\n\n\n\n\n\n\n\n\ndef forward(latent_weights, brush):\n    latent_t = transform(latent_weights, brush)\n    design_mask = generate_feasible_design_mask(latent_t, brush)\n    epsr = np.where(design_mask, 12.0, 1.0)\n\n\nsource\n\nforward\n\n forward (latent_weights, brush)\n\n\ndef loss_fn(epsr):\n    epsr = epsr.reshape((Nx, Ny))\n    simulation.eps_r = mask_combine_epsr(epsr, bg_epsr, design_region)\n    _, _, Ez = simulation.solve(source)\n    return -mode_overlap(Ez, probe) / E0\n\n\nsource\n\n\nloss_fn\n\n loss_fn (epsr)\n\n\ngrad_fn = jacobian(loss_fn, mode='reverse')\n\n\n\nOptimization\n\n# Simulate initial device\nsimulation, ax = viz_sim(epsr_total, source, slices=[input_slice, output_slice])\n\n\n\n\n\ninit_fn, update_fn, params_fn = adam(step_size)\nstate = init_fn(epsr.reshape(1, -1))\n\nthis is the optimization step:\n\nsource\n\n\nstep_fn\n\n step_fn (step, state)\n\nwe can now loop over the optimization:\n\nrange_ = trange(500)\nfor step in range_:\n    loss, state = step_fn(step, state)\n    range_.set_postfix(loss=float(loss))\n\n\n\n\n\nepsr_optimum = params_fn(state)\nepsr_optimum = epsr_optimum.reshape((Nx, Ny))\n\n\n# Simulate and show the optimal device\nepsr_optimum_total = mask_combine_epsr(epsr_optimum, bg_epsr, design_region)\nsimulation, ax = viz_sim(epsr_optimum_total, source, slices=[input_slice, output_slice])\n\n\n\n\nAt the end of the optimization we can see our final device. From the field pattern, we can easily observe that the device is doing what we intend: the even mode enters from the left and exits as the odd mode on the right.\nHowever, an additional observation is that our device’s permittivity changes continuously. This is not ideal if we wanted to fabricated our device. We’re also not constraining the minimum and maximum values of \\(\\epsilon_r\\). Thus, we need to consider alternative ways of parameterizing our device.\n\nplt.imshow(np.sqrt(epsr_optimum_total.T), cmap=\"plasma\", vmin=1, vmax=4)\nplt.ylim(*plt.ylim()[::-1])\nplt.colorbar(ticks=[1,2,3,4], label=\"n\")\nplt.xlabel(\"x\")\nplt.xlabel(\"y\")\nplt.grid(True)"
  },
  {
    "objectID": "notebooks/brushes.html",
    "href": "notebooks/brushes.html",
    "title": "Brushes",
    "section": "",
    "text": "source\n\nshow_mask\n\n show_mask (brush)\n\n\nsource\n\n\ncircular_brush\n\n circular_brush (diameter)\n\n\nshow_mask(circular_brush(13))\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\n\n\n\n\nsource\n\n\nnotched_square_brush\n\n notched_square_brush (width, notch)\n\n\nshow_mask(notched_square_brush(5, 1))"
  },
  {
    "objectID": "notebooks/ceviche_challenges.html",
    "href": "notebooks/ceviche_challenges.html",
    "title": "Ceviche Challenges",
    "section": "",
    "text": "import numpy as np\nimport ceviche_challenges\nfrom ceviche_challenges import units as u\nimport ceviche\nfrom inverse_design.brushes import notched_square_brush, circular_brush\nfrom inverse_design.conditional_generator import (\n    new_latent_design, transform\n)\nfrom tqdm.notebook import trange\n\nimport autograd\nimport autograd.numpy as npa\n\n\nimport jax\nimport jax.numpy as jnp\nfrom javiche import jaxit\nimport matplotlib.pylab as plt\nimport numpy as np\nfrom inverse_design.local_generator import generate_feasible_design_mask\nfrom jax.example_libraries.optimizers import adam\n\n\nspec = ceviche_challenges.waveguide_bend.prefabs.waveguide_bend_2umx2um_spec(\n  wg_width=400*u.nm, variable_region_size=(1600*u.nm, 1600*u.nm), cladding_permittivity=2.25\n)\nparams = ceviche_challenges.waveguide_bend.prefabs.waveguide_bend_sim_params(resolution = 25 * u.nm)\nmodel = ceviche_challenges.waveguide_bend.model.WaveguideBendModel(params, spec)\n\n\ndef forward(latent_weights, brush):\n    latent_t = transform(latent_weights, brush) #.reshape((Nx, Ny))\n    design_mask = generate_feasible_design_mask(latent_t, \n      brush, verbose=False)\n    design = (design_mask+1.0)/2.0\n    return design\n\n\nbrush = circular_brush(5)\nlatent = new_latent_design(model.design_variable_shape, bias=0.1, r=1, r_scale=1e-3)\n\n\n@jaxit()\ndef inner_loss_fn(design):\n    s_params, fields = model.simulate(design)\n    s11 = npa.abs(s_params[:, 0, 0])\n    s21 = npa.abs(s_params[:, 0, 1])\n    \n    global debug_fields\n    debug_fields = fields\n    global debug_design\n    debug_design = design\n\n    return npa.mean(s11) - npa.mean(s21)\n\ndef loss_fn(latent):\n    design = forward(latent, brush)\n    return inner_loss_fn(design)\n\n\n# Number of epochs in the optimization\nNsteps = 150\n# Step size for the Adam optimizer\ndef step_size(idx):\n  \"\"\"reducing the stepsize linearly for Nsteps (stabilize afterwards just in case)\"\"\"\n  start = 0.1\n  stop = 5e-3\n  return start*(stop/start)**(idx/Nsteps)\n\nstep_size = 0.01\n\n\ndef visualize_latent(latent):\n  global debug_design, debug_fields\n  design = forward(latent, brush)\n  s_params, fields = model.simulate(design)\n  debug_design = design\n  debug_fields = fields\n  visualize_debug()\n\ndef visualize_debug():\n  global debug_design, debug_fields\n  if not isinstance(debug_fields, np.ndarray):\n    debug_fields = debug_fields._value\n    debug_design = debug_design._value\n  ceviche.viz.abs(np.squeeze(np.asarray(debug_fields)), model.density(np.asarray(debug_design)))\n  plt.grid()\n  plt.show()\n\n\ngrad_fn = jax.grad(loss_fn)\n\ninit_fn, update_fn, params_fn = adam(step_size)\nstate = init_fn(latent) #.flatten()\n#value_and_grad seems to have a problem. Figure out why!\n\ndef step_fn(step, state):\n    latent = params_fn(state) # we need autograd arrays here...\n    grads = grad_fn(latent)\n    loss = loss_fn(latent)\n    #loss = loss_fn(latent)\n\n    optim_state = update_fn(step, grads, state)\n    # optim_latent = params_fn(optim_state)\n    # optim_latent = optim_latent/optim_latent.std()\n\n    visualize_debug()\n    return loss, optim_state\n\n\nlatent = params_fn(state)\nvisualize_latent(latent)\n\n\nrange_ = trange(Nsteps)\nlosses = np.ndarray(Nsteps)\nfor step in range_:\n    loss, state = step_fn(step, state)\n    losses[step] = loss\n    range_.set_postfix(loss=float(loss))\n\n\nlatent = params_fn(state)\ndesign = forward(latent, brush)\ns_params, fields = model.simulate(design)\nepsr = model.epsilon_r(design)\nceviche.viz.abs(np.squeeze(fields), model.density(design))\nplt.grid()"
  },
  {
    "objectID": "notebooks/conditional_generator.html",
    "href": "notebooks/conditional_generator.html",
    "title": "Conditional Generator",
    "section": "",
    "text": "my_brush = circular_brush(7)\nmy_brush = notched_square_brush(5, 1)\nshow_mask(my_brush)\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)"
  },
  {
    "objectID": "notebooks/conditional_generator.html#latent-design",
    "href": "notebooks/conditional_generator.html#latent-design",
    "title": "Conditional Generator",
    "section": "Latent Design",
    "text": "Latent Design\nIt’s not very well explained in the paper what the latent design actually is. In this case we’ll just assume it’s an array of the same shape as the design, but with continuous values between 0 and 1.\n\nsource\n\nnew_latent_design\n\n new_latent_design (shape, bias=0, r=None, r_scale=1)\n\n\nseed=42\nm,n = 30, 30\nlatent = new_latent_design((m,n), r=seed)\nprint(latent[:3, :3])\nplt.imshow(latent, vmin=-3, vmax=3, cmap=\"Greys\")\nplt.colorbar()\nplt.show()\n\n[[ 0.49671414 -0.1382643   0.64768857]\n [-0.6017066   1.8522782  -0.01349723]\n [-0.47917423 -0.18565898 -1.1063349 ]]\n\n\n\n\n\n\n#with open(f\"latent{seed}_{m}x{n}.bin\", \"wb\") as file:\n#    file.write(latent.tobytes())"
  },
  {
    "objectID": "notebooks/conditional_generator.html#transform",
    "href": "notebooks/conditional_generator.html#transform",
    "title": "Conditional Generator",
    "section": "Transform",
    "text": "Transform\nThe transform removes some of the noise from the latent design.\n\nsource\n\ntransform\n\n transform (latent, brush, beta=5.0)\n\n\nlatent_t = transform(latent, my_brush)\nprint(latent_t[:3, :3])\nplt.imshow(latent_t, cmap=\"Greys\", vmin=-1, vmax=1)\nplt.colorbar()\nplt.show()\n\n[[ 0.3590585   0.21954855  0.19020812]\n [ 0.35060647  0.0249535   0.25184518]\n [ 0.01658658 -0.10942358 -0.0914182 ]]"
  },
  {
    "objectID": "notebooks/conditional_generator.html#conditional-generator",
    "href": "notebooks/conditional_generator.html#conditional-generator",
    "title": "Conditional Generator",
    "section": "Conditional Generator",
    "text": "Conditional Generator\n\nsource\n\nconditional_algirithm_step\n\n conditional_algirithm_step (latent_t, design, brush, verbose=False)\n\n\nsource\n\n\nconditional_generator\n\n conditional_generator (latent_t, brush, verbose=False)\n\n\nsource\n\n\ngenerate_feasible_design\n\n generate_feasible_design (latent_t, brush, verbose=False, backend='auto')\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlatent_t\n\n\n\n\n\nbrush\n\n\n\n\n\nverbose\nbool\nFalse\n\n\n\nbackend\nstr\nauto\nbackend: ‘auto’, ‘rust’, ‘python’\n\n\n\n\nmy_design\n\nCPU times: user 8.37 ms, sys: 3.68 ms, total: 12.1 ms\nWall time: 12.6 ms\n\n\n\n\n\n\n\n\n\nlatent_t = transform(latent, my_brush)\nplt.imshow(latent_t, cmap=\"Greys\", vmin=-1, vmax=1)\nplt.colorbar()\nplt.show()\n\n\n\n\nIn practice however, it’s probably more useful to generate a design mask straight away (+1.0 for solid, -1.0 for void):\n\nsource\n\n\ngenerate_feasible_design_mask_\n\n generate_feasible_design_mask_ (latent_t, brush, backend='auto')\n\n\nmy_design_mask = generate_feasible_design_mask_(latent_t, my_brush)\nmy_design_mask.shape\n\n(30, 30)\n\n\n\nplt.imshow(my_design_mask, cmap=\"Greys\", vmin=-1, vmax=1)\nplt.colorbar()\nplt.show()"
  },
  {
    "objectID": "notebooks/conditional_generator.html#straight-through-estimator",
    "href": "notebooks/conditional_generator.html#straight-through-estimator",
    "title": "Conditional Generator",
    "section": "Straight Through Estimator",
    "text": "Straight Through Estimator\nWe cannot just call jax.grad on our feasible design mask generator. All gradients will be zero as our mask generator is not differentiable…\n\ndef my_test_loss_function_(latent_t, brush):\n    return generate_feasible_design_mask_(latent_t, brush, backend='python').mean()\n\n\ng = jax.grad(my_test_loss_function_)\nassert (g(latent_t, my_brush) == 0).all()\n\nMoreover, if we would have chosen the Rust-based backend, the above cell would have errored out…\nIn stead, we use a straight-through estimator (a.k.a. identity function) for our feasible design:\n\nsource\n\ngenerate_feasible_design_mask\n\n generate_feasible_design_mask (latent_t, brush)\n\n\nsource\n\n\ngenerate_feasible_design_mask_jvp\n\n generate_feasible_design_mask_jvp (primals, tangents)\n\n\ndef my_test_loss_function(latent_t, brush):\n    return generate_feasible_design_mask(latent_t, brush).mean()\n\n\ng = jax.grad(my_test_loss_function)\nassert (g(latent_t, my_brush) != 0).any()"
  },
  {
    "objectID": "notebooks/utils.html",
    "href": "notebooks/utils.html",
    "title": "Utils",
    "section": "",
    "text": "source\n\n\n\n conv (lhs, rhs, window_strides=(1, 1), padding='SAME', **kwargs)\n\n\nsource\n\n\n\n\n conv (lhs, rhs, window_strides=(1, 1), padding='SAME', **kwargs)\n\n\nsource\n\n\n\n\n conv (lhs, rhs, window_strides=(1, 1), padding='SAME', **kwargs)\n\n\nsource\n\n\n\n\n dilute (touches, brush)"
  },
  {
    "objectID": "notebooks/utils.html#random",
    "href": "notebooks/utils.html#random",
    "title": "Utils",
    "section": "Random",
    "text": "Random\nI just can’t be bothered doing this the JAX way…\n\nsource\n\nrandn\n\n randn (shape, r=None, dtype=<class 'float'>)\n\n\nsource\n\n\nrand\n\n rand (shape, r=None, dtype=<class 'float'>)"
  },
  {
    "objectID": "notebooks/utils.html#argmax-argmin",
    "href": "notebooks/utils.html#argmax-argmin",
    "title": "Utils",
    "section": "Argmax / Argmin",
    "text": "Argmax / Argmin\n\nsource\n\nargmax2d\n\n argmax2d (arr2d)\n\n\nsource\n\n\nargmin2d\n\n argmin2d (arr2d)"
  },
  {
    "objectID": "notebooks/inverse_design_local.html",
    "href": "notebooks/inverse_design_local.html",
    "title": "Inverse Design Local",
    "section": "",
    "text": "This notebook overwrites the inverse design notebook to use the local_generator"
  },
  {
    "objectID": "notebooks/inverse_design_local.html#prepare",
    "href": "notebooks/inverse_design_local.html#prepare",
    "title": "Inverse Design Local",
    "section": "Prepare",
    "text": "Prepare\n\nbrush = notched_square_brush(5, 1)\nlatent = new_latent_design((Nx, Ny), r=1)\n\n\n# Simulate initial device\nsimulation, ax = viz_sim(epsr_total, source, slices=[input_slice, output_slice])\n_, _, Ez = simulation.solve(source)\nE0 = mode_overlap(Ez, probe)"
  },
  {
    "objectID": "notebooks/inverse_design_local.html#optimization",
    "href": "notebooks/inverse_design_local.html#optimization",
    "title": "Inverse Design Local",
    "section": "Optimization",
    "text": "Optimization\n\nfrom inverse_design.local_generator import dilate\n\n\nbg_mask = np.logical_or(bg_epsr>2, design_region)\neroded = dilate(np.logical_not(bg_mask), brush)\ndilated = dilate(bg_epsr>2, brush)\n\ninit_t_s = np.logical_not(np.logical_or(eroded, design_region)) \ninit_t_v = np.logical_not(np.logical_or(dilated, design_region)) \n# plt.imshow(init_t_s, vmax=1, vmin=0)\n# plt.figure()\n# plt.imshow(init_t_v, vmax=1, vmin=0)\n\n\nlatent_t = transform(latent, brush)\ngenerate_feasible_design_mask(\n  latent_t, brush, init_touches_solid=init_t_s.copy(), \n  init_touches_void=init_t_v.copy(), verbose=False)\n\n\ndef forward(latent_weights, brush):\n    latent_t = transform(latent_weights, brush) #.reshape((Nx, Ny))\n    design_mask = generate_feasible_design_mask(latent_t, \n      brush, init_touches_solid=init_t_s, init_touches_void=init_t_v, verbose=False)\n    epsr = (design_mask+1.0)/2.0*(12-1) +1 \n    # complicated expression to avoid where clause, as it caused problems with differentiation\n    # why did the np.where clause lead to 0 gradients?\n    return epsr\n\n\n@jaxit(cache=True)\ndef inner_loss_fn(epsr):\n    #print(\".\")\n    simulation.eps_r = mask_combine_epsr(epsr, bg_epsr, design_region)\n    _, _, Ez = simulation.solve(source)\n\n    return -mode_overlap(Ez, probe) / E0\n\ndef loss_fn(latent):\n    epsr = forward(latent, brush)\n    # def debug_plot(epsr):\n    #   plt.figure(figsize=(0.5,0.5))\n    #   plt.imshow(epsr)\n    #   plt.axis(\"off\")\n    #   plt.show()\n    # jax.debug.callback(debug_plot, epsr)\n    return inner_loss_fn(epsr)\n\n\nloss_fn(latent)\n\n\ninit_fn, update_fn, params_fn = adam(step_size)\nstate = init_fn(latent) #.flatten()\n\nthis is the optimization step:\n\ndef step_fn(step, state):\n    latent = params_fn(state) # we need autograd arrays here...\n    loss, grads = grad_fn(latent)\n    #loss = loss_fn(latent)\n    optim_state = update_fn(step, grads, state)\n    optim_latent = params_fn(optim_state)\n    optim_latent = optim_latent/optim_latent.std()\n    return loss, init_fn(optim_latent)\n\nwe can now loop over the optimization:\n\n\nCode\nrange_ = trange(Nsteps)\nlosses = np.ndarray(Nsteps)\nfor step in range_:\n    loss, state = step_fn(step, state)\n    losses[step] = loss\n    range_.set_postfix(loss=float(loss))\n\n\n\n# Simulate and show the optimal device\nepsr_optimum = forward(params_fn(state), brush)\nepsr_optimum_total = mask_combine_epsr(epsr_optimum, bg_epsr, design_region)\nsimulation, ax = viz_sim(epsr_optimum_total, source, slices=[input_slice, output_slice])\n\n\nplt.plot(losses)\nplt.xlabel(\"step number\")\nplt.ylabel(\"loss\")"
  },
  {
    "objectID": "notebooks/design.html",
    "href": "notebooks/design.html",
    "title": "Design",
    "section": "",
    "text": "UNASSIGNED = 0\nVOID = 1\nSOLID = 2\nPIXEL_IMPOSSIBLE = 3\nPIXEL_EXISTING = 4\nPIXEL_POSSIBLE = 5\nPIXEL_REQUIRED = 6\nTOUCH_REQUIRED = 7\nTOUCH_INVALID = 8\nTOUCH_EXISTING = 9\nTOUCH_VALID = 10\nTOUCH_FREE = 11\nTOUCH_RESOLVING = 12\n\n\nsource\n\nDesign\n\n Design (void_pixels:jax.Array, solid_pixels:jax.Array,\n         void_touches:jax.Array, solid_touches:jax.Array)\n\n\nsource\n\n\nnew_design\n\n new_design (shape)\n\n\nsource\n\n\ndesign_mask\n\n design_mask (design, dtype=<class 'float'>)\n\n\nsource\n\n\nvisualize\n\n visualize (design, grid=True)\n\n\nmy_brush = notched_square_brush(5, 1)\nshow_mask(my_brush)\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\n\n\n\n\nstep1 = lambda: new_design((6, 8))\nstep1()\n\n\n\n\n\n\n\n\nsource\n\n\nadd_void_touch\n\n add_void_touch (design, brush, pos)\n\n\nstep2 = lambda: add_void_touch(step1(), my_brush, (0, 6))\nstep2()\n\n\n\n\n\n\n\n\nsource\n\n\ntake_free_void_touches\n\n take_free_void_touches (design, brush)\n\n\nstep3 = lambda: take_free_void_touches(step2(), my_brush)\nstep3()\n\n\n\n\n\n\n\n\nsource\n\n\ninvert_design\n\n invert_design (design)\n\n\ninvert_design(step3())\n\n\n\n\n\n\n\n\nsource\n\n\nadd_solid_touch\n\n add_solid_touch (design, brush, pos)\n\n\nsource\n\n\ntake_free_solid_touches\n\n take_free_solid_touches (design, brush)\n\n\nstep4 = lambda: add_solid_touch(step3(), my_brush, (0, 0))\nstep4()\n\n\n\n\n\n\n\n\nstep5 = lambda: add_void_touch(step4(), my_brush, (4, 6))\nstep5()\n\n\n\n\n\n\n\n\nstep6 = lambda: take_free_void_touches(step5(), my_brush)\nstep6()\n\n\n\n\n\n\n\n\nstep7 = lambda: add_void_touch(step6(), my_brush, (4, 4))\nstep7()\n\n\n\n\n\n\n\n\nstep8 = lambda: take_free_void_touches(step7(), my_brush)\nstep8()\n\n\n\n\n\n\n\n\nstep9 = lambda: add_void_touch(step8(), my_brush, (5, 0))\nstep9()\n\n\n\n\n\n\n\n\nstep10 = lambda: take_free_void_touches(step9(), my_brush)\nstep10()\n\n\n\n\n\n\n\n\nstep11 = lambda: add_void_touch(step10(), my_brush, (2, 5))\nstep11()\n\n\n\n\n\n\n\n\nstep12 = lambda: take_free_void_touches(step11(), my_brush)\nstep12()"
  },
  {
    "objectID": "notebooks/direct_optimization.html",
    "href": "notebooks/direct_optimization.html",
    "title": "Direct Optimization",
    "section": "",
    "text": "shape = (M, N) = (30, 30)\n\n\n\nLet’s - for now - just try to find a pre-defined design target (which we will construct with our generator)…\n\nbrush_target = notched_square_brush(5, 1)\nlatent_target = new_latent_design(shape, r=42)\nlatent_target_t = transform(latent_target, brush_target)\nmask_target = generate_feasible_design_mask(latent_target_t, brush_target)\n\nplt.imshow(mask_target, cmap=\"Greys\")\nplt.colorbar()\nplt.show()\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\n\n\n\n\n\n\n\nbrush_input = notched_square_brush(5, 1)\nlatent_input = new_latent_design(shape, r=0)\nlatent_input_t = transform(latent_input, brush_input)\nmask_input = generate_feasible_design_mask(latent_input_t, brush_target)\n\nplt.imshow(mask_input, cmap=\"Greys\")\nplt.colorbar()\nplt.show()"
  },
  {
    "objectID": "notebooks/direct_optimization.html#loss-functions",
    "href": "notebooks/direct_optimization.html#loss-functions",
    "title": "Direct Optimization",
    "section": "Loss Functions",
    "text": "Loss Functions\n\nsource\n\nmse\n\n mse (x, y)\n\n\nsource\n\n\nhuber_loss\n\n huber_loss (x, y, delta=0.5)"
  },
  {
    "objectID": "notebooks/direct_optimization.html#optimization",
    "href": "notebooks/direct_optimization.html#optimization",
    "title": "Direct Optimization",
    "section": "Optimization",
    "text": "Optimization\nthe loss function defines what we’re optimizing.\n\ndef forward(latent, brush):\n    latent_t = transform(latent, brush)\n    design_mask = generate_feasible_design_mask(latent_t, brush) # differentiable through STE\n    return design_mask\n    \ndef loss_fn(latent, brush, target_mask):\n    design_mask = forward(latent, brush)\n    return huber_loss(design_mask, target_mask)\n\nloss_fn(latent_input, brush_input, mask_target)\n\nArray(0.40687042, dtype=float32)\n\n\nusing jax, it’s easy to get the gradient function.\n\ngrad_fn = jax.grad(loss_fn, argnums=0)\n\nlet’s use an Adam optimizer\n\ninit_fn, update_fn, params_fn = adam(0.1)\nstate = init_fn(latent_input)\n\nthis is the optimization step:\n\ndef step_fn(step, state, brush, mask_target):\n    latent = params_fn(state)\n    loss = loss_fn(latent, brush, mask_target)\n    grads = grad_fn(latent, brush, mask_target)\n    optim_state = update_fn(step, grads, state)\n    return loss, optim_state\n\nwe can now loop over the optimization:\n\nrange_ = trange(10) # reduced iterations, so that tests run faster\nfor step in range_:\n    loss, state = step_fn(step, state, brush_input, mask_target)\n    range_.set_postfix(loss=float(loss))\nlatent_input = params_fn(state)\n\n\n\n\n\nplt.imshow(mask_target, cmap=\"Greys\", vmin=-1, vmax=1)\nplt.colorbar()\nplt.show()\n\n\n\n\n\nplt.imshow(forward(latent_input, brush_input), cmap=\"Greys\", vmin=-1, vmax=1)\nplt.colorbar()\nplt.show()\n\n\n\n\n\nloss_fn(latent_input, brush_input, mask_target)\n\nArray(0.03643624, dtype=float32)"
  },
  {
    "objectID": "notebooks/naive_inverse_design.html",
    "href": "notebooks/naive_inverse_design.html",
    "title": "Naive Inverse Design",
    "section": "",
    "text": "This notebook was adapted from Ceviche’s inverse design introduction to use a JAX-based optimization loop in stead of the default Ceviche optimization loop."
  },
  {
    "objectID": "notebooks/naive_inverse_design.html#introduction-multi-mode-waveguides",
    "href": "notebooks/naive_inverse_design.html#introduction-multi-mode-waveguides",
    "title": "Naive Inverse Design",
    "section": "Introduction: multi-mode waveguides",
    "text": "Introduction: multi-mode waveguides\nThe ceviche package has a built-in method insert_mode() that allows different modes to be inserted as sources.\nBelow, we demonstrate how this functionality can be used to excite the first and second order modes of a straight waveguide:\n\n# Define simulation parameters (see above)\nomega = 2 * np.pi * 200e12\ndl = 25e-9\n\nNx = 200\nNy = 120\nNpml = 20\n\n# Define permittivity for a straight waveguide\nepsr = np.ones((Nx, Ny))\nepsr[:, 50:67] = 12.0\n\n# Source position\nsrc_y = np.arange(20, 100)\nsrc_x = 30 * np.ones(src_y.shape, dtype=int)\n\n# Source for mode 1\nsource1 = insert_mode(omega, dl, src_x, src_y, epsr, m=1)\n\n# Source for mode 2\nsource2 = insert_mode(omega, dl, src_x, src_y, epsr, m=2)\n\n# Run the simulation exciting mode 1\nsimulation = ceviche.fdfd_ez(omega, dl, epsr, [Npml, Npml])\nHx, Hy, Ez = simulation.solve(source1)\n\n# Visualize the electric field\nax = ceviche.viz.real(Ez, outline=epsr, cmap=\"RdBu_r\")\nax.plot(src_x, src_y, \"k\")\n\n# Run the simulation exciting mode 2\nsimulation = ceviche.fdfd_ez(omega, dl, epsr, [Npml, Npml])\nHx, Hy, Ez = simulation.solve(source2)\n\n# Visualize the electric field\nax = ceviche.viz.real(Ez, outline=epsr, cmap=\"RdBu_r\")\nax.plot(src_x, src_y, \"k\")\n\nplt.show()"
  },
  {
    "objectID": "notebooks/naive_inverse_design.html#simulation-and-optimization-parameters",
    "href": "notebooks/naive_inverse_design.html#simulation-and-optimization-parameters",
    "title": "Naive Inverse Design",
    "section": "Simulation and optimization parameters",
    "text": "Simulation and optimization parameters\nOur toy optimization problem will be to design a device that converts an input in the first-order mode into an output as the second-order mode. First, we define the parameters of our device and optimization:\n\n# Angular frequency of the source in Hz\nomega = 2 * np.pi * 200e12\n# Spatial resolution in meters\ndl = 40e-9\n# Number of pixels in x-direction\nNx = 100\n# Number of pixels in y-direction\nNy = 100\n# Number of pixels in the PMLs in each direction\nNpml = 20\n# Initial value of the structure's relative permittivity\nepsr_init = 12.0\n# Space between the PMLs and the design region (in pixels)\nspace = 10\n# Width of the waveguide (in pixels)\nwg_width = 12\n# Length in pixels of the source/probe slices on each side of the center point\nspace_slice = 8\n# Number of epochs in the optimization\nNsteps = 100\n# Step size for the Adam optimizer\nstep_size = 1e-2\n\n\nUtility functions\nWe now define some utility functions for initialization and optimization:\n\nsource\n\n\ninit_domain\n\n init_domain (Nx=100, Ny=100, Npml=20, space=10, wg_width=12,\n              space_slice=8)\n\nInitializes the domain and design region\nspace : The space between the PML and the structure wg_width : The feed and probe waveguide width space_slice : The added space for the probe and source slices\n\nsource\n\n\nmask_combine_epsr\n\n mask_combine_epsr (epsr, bg_epsr, design_region)\n\nUtility function for combining the design region epsr and the background epsr\n\nsource\n\n\nviz_sim\n\n viz_sim (epsr, source, slices=[])\n\nSolve and visualize a simulation with permittivity ‘epsr’\n\nsource\n\n\nmode_overlap\n\n mode_overlap (E1, E2)\n\nDefines an overlap integral between the simulated field and desired field\n\n\nVisualizing the starting device\nWe can visualize what our starting device looks like and how it behaves. Our device is initialized by the init_domain() function which was defined several cells above.\n\n# Initialize the parametrization rho and the design region\nepsr, bg_epsr, design_region, input_slice, output_slice = init_domain(\n    Nx, Ny, Npml, space=space, wg_width=wg_width, space_slice=space_slice\n)\n\nepsr_total = mask_combine_epsr(epsr, bg_epsr, design_region)\n\n# Setup source\nsource = insert_mode(omega, dl, input_slice.x, input_slice.y, epsr_total, m=1)\n\n# Setup probe\nprobe = insert_mode(omega, dl, output_slice.x, output_slice.y, epsr_total, m=2)\n\n\n# Simulate initial device\nsimulation, ax = viz_sim(epsr_total, source, slices=[input_slice, output_slice])\n\n# get normalization factor (field overlap before optimizing)\n_, _, Ez = simulation.solve(source)\nE0 = mode_overlap(Ez, probe)\n\n\n\n\n\n\nDefine objective function\nWe will now define our objective function. This is a scalar-valued function which our optimizer uses to improve the device’s performance.\nOur objective function will consist of maximizing an overlap integral of the field in the output waveguide of the simulated device and the field of the waveguide’s second order mode (minimizing the negative overlap). The function takes in a single argument, epsr and returns the value of the overlap integral. The details of setting the permittivity and solving for the fields happens inside the objective function.\n\nsource\n\n\nloss_fn\n\n loss_fn (epsr)\n\nObjective function called by optimizer\n\nTakes the epsr distribution as input\nRuns the simulation\nReturns the overlap integral between the output wg field and the desired mode field\n\n\n\nRun optimization\nThis is where our discussion deviates from the original discussion by the ceviche maintainers. In our case, we would like the optimization to fit in a JAX-based optimization scheme:\n\n# Simulate initial device\nsimulation, ax = viz_sim(epsr_total, source, slices=[input_slice, output_slice])\n\n\n\n\n\ngrad_fn = jacobian(loss_fn, mode='reverse')\n\n\ninit_fn, update_fn, params_fn = adam(step_size)\nstate = init_fn(epsr.reshape(1, -1))\n\nNo GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n\n\nthis is the optimization step:\n\nsource\n\n\nstep_fn\n\n step_fn (step, state)\n\nwe can now loop over the optimization:\n\nrange_ = trange(30)\nfor step in range_:\n    loss, state = step_fn(step, state)\n    range_.set_postfix(loss=float(loss))\n\n\n\n\n\nloss\n\n-6146280.518657835\n\n\n\nepsr_optimum = params_fn(state)\nepsr_optimum = epsr_optimum.reshape((Nx, Ny))\n\n\n# Simulate and show the optimal device\nepsr_optimum_total = mask_combine_epsr(epsr_optimum, bg_epsr, design_region)\nsimulation, ax = viz_sim(epsr_optimum_total, source, slices=[input_slice, output_slice])\n\n\n\n\nAt the end of the optimization we can see our final device. From the field pattern, we can easily observe that the device is doing what we intend: the even mode enters from the left and exits as the odd mode on the right.\nHowever, an additional observation is that our device’s permittivity changes continuously. This is not ideal if we wanted to fabricated our device. We’re also not constraining the minimum and maximum values of \\(\\epsilon_r\\). Thus, we need to consider alternative ways of parameterizing our device.\n\nplt.imshow(np.sqrt(epsr_optimum_total.T), cmap=\"plasma\", vmin=1, vmax=4)\nplt.ylim(*plt.ylim()[::-1])\nplt.colorbar(ticks=[1,2,3,4], label=\"n\")\nplt.xlabel(\"x\")\nplt.xlabel(\"y\")\nplt.grid(True)"
  },
  {
    "objectID": "notebooks/naive_generator.html",
    "href": "notebooks/naive_generator.html",
    "title": "Naive Generator",
    "section": "",
    "text": "import numpy as np\nimport scipy.ndimage\nimport matplotlib.pyplot as plt\nimport time"
  },
  {
    "objectID": "notebooks/naive_generator.html#generating-a-latent-space-representation",
    "href": "notebooks/naive_generator.html#generating-a-latent-space-representation",
    "title": "Naive Generator",
    "section": "Generating a latent space representation",
    "text": "Generating a latent space representation\nTo make it more “understandable” where material is placed we generate a slowly varying landscape by interpolation of a low resolution map.\n\nfeatures = 8\nzoom = 16\nheatmap = np.random.random((features,features))-0.5\nlarge_heatmap = scipy.ndimage.zoom(heatmap, zoom)\nplt.imshow(large_heatmap)\nplt.xlabel(\"x\")\nplt.ylabel(\"y\")\nplt.grid()"
  },
  {
    "objectID": "notebooks/naive_generator.html#generating-the-brush",
    "href": "notebooks/naive_generator.html#generating-the-brush",
    "title": "Naive Generator",
    "section": "Generating the brush",
    "text": "Generating the brush\n\nkernel_size=9\nbrush = np.ones((kernel_size, kernel_size))\nbrush[0,0] = 0\nbrush[0,-1] = 0\nbrush[-1,0] = 0\nbrush[-1,-1] = 0\n\nnx, ny = brush.shape\n\nplt.imshow(brush)\nax = plt.gca()\nax.set_yticks(np.arange(nx)+0.5)\nax.set_yticklabels([\"\" for i in range(nx)])\nax.set_xticks(np.arange(ny)+0.5)\nax.set_xticklabels([\"\" for i in range(ny)])\nax.set_yticks(np.arange(nx), minor=True)\nax.set_yticklabels([f\"{i}\" for i in range(nx)], minor=True)\nax.set_xticks(np.arange(ny), minor=True)\nax.set_xticklabels([f\"{i}\" for i in range(ny)], minor=True)\nplt.grid()"
  },
  {
    "objectID": "notebooks/naive_generator.html#running-the-generator",
    "href": "notebooks/naive_generator.html#running-the-generator",
    "title": "Naive Generator",
    "section": "Running the Generator",
    "text": "Running the Generator\n\ndef dilate(img, brush):\n    global time_dilate\n    time_dilate -= time.process_time() \n    dil = scipy.ndimage.morphology.binary_dilation(img, brush)\n    time_dilate += time.process_time() \n    return dil\n\ndef existing_pixels(touches, brush):\n    return dilate(touches, brush)\n\ndef impossible_touches(existing_other, brush):\n    return dilate(existing_other, brush)\n\ndef valid_touches(impossible, touches):\n    return np.logical_and(np.logical_not(impossible), np.logical_not(touches))\n\ndef possible_pixels(valid, touches, brush):\n    possible_touches = np.logical_or(touches, valid)\n    return dilate(possible_touches, brush)\n\ndef required_pixels(existing, possible_other):\n    return np.logical_and(np.logical_not(existing), np.logical_not(possible_other))\n\ndef resolving_touches(required, valid, brush):\n    return np.logical_and(dilate(required, brush), valid)\n\ndef free_touches(possible_other, existing_other, valid, brush):\n    dilated = dilate(np.logical_or(possible_other, existing_other), brush)\n    return np.logical_and(np.logical_not(dilated), valid)\n\ndef select_single(s_valid, v_valid, s_suggest, v_suggest, brush, t_s, t_v):\n    s_weights = scipy.ndimage.convolve(s_suggest, brush)\n    v_weights = -scipy.ndimage.convolve(v_suggest, brush)\n\n    s_weights[np.logical_not(s_valid)] = np.nan\n    v_weights[np.logical_not(v_valid)] = np.nan\n\n    max_s = max_v = -np.inf\n    if s_valid.any():\n        max_pos_s = np.nanargmax(s_weights)\n        max_s = s_weights.flat[max_pos_s]\n    \n    if v_valid.any():\n        max_pos_v = np.nanargmax(v_weights)\n        max_v = v_weights.flat[max_pos_v]\n\n    if  max_s > max_v:\n        t_s.flat[max_pos_s] = True\n    else:\n        t_v.flat[max_pos_v] = True\n\n    return t_s, t_v\n\ns_suggest = large_heatmap.copy()\nv_suggest = large_heatmap.copy()\nt_s = np.zeros_like(s_suggest).astype(bool)\nt_v = t_s.copy()\n\ntime_update = 0\ntime_select = 0 \ntime_dilate = 0\ntime_existing = 0\ntime_impossible = 0\ntime_valid = 0\ntime_possible = 0\ntime_required = 0\ntime_resolving = 0\ntime_free = 0\n\ndebug = True\ndef log(*args):\n  if debug:\n    print(*args)\n\nfor i in range(10000):\n    time_update -= time.process_time() \n\n    time_existing -= time.process_time() \n    p_s_existing = existing_pixels(t_s, brush)\n    p_v_existing = existing_pixels(t_v, brush)\n    time_existing += time.process_time() \n\n    s_suggest[p_s_existing] = 0\n    v_suggest[p_v_existing] = 0\n\n    time_impossible -= time.process_time() \n    t_s_impossible = impossible_touches(p_v_existing, brush)\n    t_v_impossible = impossible_touches(p_s_existing, brush)\n    time_impossible += time.process_time() \n\n    time_valid -= time.process_time() \n    t_s_valid = valid_touches(t_s_impossible, t_s)\n    t_v_valid = valid_touches(t_v_impossible, t_v)\n    time_valid += time.process_time() \n\n    time_possible -= time.process_time() \n    p_s_possible = possible_pixels(t_s_valid,t_s,brush)\n    p_v_possible = possible_pixels(t_v_valid,t_v,brush)\n    time_possible += time.process_time() \n\n    time_required -= time.process_time() \n    p_s_required = required_pixels(p_s_existing, p_v_possible)\n    p_v_required = required_pixels(p_v_existing, p_s_possible)\n    time_required += time.process_time() \n\n    time_resolving -= time.process_time() \n    t_s_resolving = resolving_touches(p_s_required, t_s_valid, brush)\n    t_v_resolving = resolving_touches(p_v_required, t_v_valid, brush)\n    time_resolving += time.process_time() \n\n    time_free -= time.process_time() \n    t_s_free = free_touches(p_v_possible, p_v_existing, t_s_valid, brush)\n    t_v_free = free_touches(p_s_possible, p_s_existing, t_v_valid, brush)\n    time_free += time.process_time() \n\n    time_update += time.process_time() \n    time_select -= time.process_time() \n\n    if t_s_free.any() or t_v_free.any():\n        log(f\"{i}: free\")\n        t_s = np.logical_or(t_s, t_s_free)\n        t_v = np.logical_or(t_v, t_v_free)\n    elif t_s_resolving.any() or t_v_resolving.any():\n        log(f\"{i}: resolving\")\n        t_s, t_v = select_single(t_s_resolving, t_v_resolving, s_suggest, v_suggest, brush, t_s, t_v)\n    elif t_s_valid.any() or t_v_valid.any():\n        log(f\"{i}: valid\")\n        t_s, t_v = select_single(t_s_valid, t_v_valid, s_suggest, v_suggest, brush, t_s, t_v)\n    else:\n        print(\"finished\")\n        time_select += time.process_time() \n        break\n\n    time_select += time.process_time() \n\n\nplt.figure(figsize = (6,9))\nplt.subplot(321)\nplt.title(\"Solid\")\nplt.imshow(p_s_existing)\nplt.subplot(322)\nplt.title(\"Void\")\nplt.imshow(p_v_existing)\nplt.subplot(323)\nplt.title(\"Solid Touches\")\nplt.imshow(t_s)\nplt.subplot(324)\nplt.title(\"Void Touches\")\nplt.imshow(t_v)\nplt.subplot(325)\nplt.imshow(large_heatmap)\n\n/tmp/ipykernel_3582/3885273807.py:4: DeprecationWarning: Please use `binary_dilation` from the `scipy.ndimage` namespace, the `scipy.ndimage.morphology` namespace is deprecated.\n  dil = scipy.ndimage.morphology.binary_dilation(img, brush)\n\n\n0: valid\n1: valid\n2: free\n3: valid\n4: valid\n5: resolving\n6: free\n7: valid\n8: valid\n\n\n9: resolving\n10: free\n11: valid\n12: valid\n13: free\n14: valid\n15: free\n16: valid\n17: valid\n18: free\n19: valid\n20: resolving\n21: free\n22: valid\n\n\n23: valid\n24: valid\n25: resolving\n26: free\n27: valid\n28: valid\n29: valid\n30: resolving\n31: free\n32: valid\n33: valid\n34: free\n35: valid\n\n\n36: resolving\n37: free\n38: valid\n39: free\n40: valid\n41: valid\n42: free\n43: valid\n44: free\n45: valid\n46: free\n47: resolving\n48: free\n49: valid\n\n\n50: free\n51: valid\n52: resolving\n53: free\n54: valid\n55: free\n56: valid\n57: valid\n\n\n58: valid\n59: free\n60: valid\n61: free\n62: valid\n63: free\n64: valid\n65: valid\n\n\n66: free\n67: resolving\n68: free\n69: resolving\n70: free\n71: resolving\n72: free\n73: valid\n74: free\n75: valid\n76: free\n77: valid\n78: free\n\n\n79: resolving\n80: resolving\n81: free\n82: resolving\n83: free\n84: valid\n85: free\n86: valid\n87: free\n88: valid\n89: free\n90: valid\n91: free\n92: valid\n93: free\n\n\n94: valid\n95: resolving\n96: free\n97: valid\n98: resolving\n99: free\n100: valid\n101: valid\n\n\n102: free\n103: valid\n104: free\n105: valid\n106: resolving\n107: free\n108: valid\n109: free\n\n\n110: valid\n111: free\n112: valid\n113: free\n114: valid\n115: free\n116: valid\n117: free\n118: valid\n119: free\n120: valid\n121: free\n122: resolving\n123: resolving\n\n\n124: free\n125: resolving\n126: free\n127: valid\n128: free\n129: valid\n130: valid\n131: free\n\n\n132: valid\n133: free\n134: valid\n135: free\n136: valid\n137: valid\n138: free\n139: valid\n140: free\n141: resolving\n142: free\n143: valid\n\n\n144: free\n145: valid\n146: valid\n147: free\n148: resolving\n149: free\n150: resolving\n151: free\n152: valid\n153: free\n154: resolving\n155: free\n156: resolving\n\n\n157: free\n158: valid\n159: free\n160: valid\n161: free\n162: valid\n163: free\n164: valid\n165: free\n166: valid\n167: resolving\n168: free\n169: valid\n\n\n170: valid\n171: free\n172: valid\n173: resolving\n174: free\n175: valid\n176: free\n177: valid\n178: free\n\n\n179: valid\n180: free\n181: valid\n182: free\n183: valid\n184: free\n185: valid\n186: free\n\n\n187: valid\n188: valid\n189: valid\n190: free\n191: valid\n192: resolving\n193: free\n194: valid\n195: free\n196: valid\n197: free\n198: valid\n\n\n199: free\n200: valid\n201: free\n202: valid\n203: valid\n204: free\n205: valid\n206: free\n207: resolving\n208: free\n209: valid\n210: resolving\n211: free\n212: valid\n213: free\n214: valid\n\n\n215: free\n216: valid\n217: free\n218: resolving\n219: resolving\n220: free\n221: resolving\n222: free\n\n\n223: resolving\n224: free\n225: resolving\n226: free\n227: resolving\n228: free\n229: valid\n230: resolving\n\n\n231: free\n232: valid\n233: free\n234: valid\n235: free\n236: valid\n237: free\n238: valid\n239: free\n240: valid\n\n\n241: free\n242: resolving\n243: resolving\n244: free\n245: resolving\n246: free\n247: resolving\n248: free\n249: valid\n250: free\n251: valid\n252: free\n\n\n253: valid\n254: free\n255: valid\n256: resolving\n257: free\n258: valid\n259: free\n260: valid\n261: free\n262: valid\n263: free\n264: valid\n\n\n265: free\n266: valid\n267: free\n268: valid\n269: resolving\n270: free\n271: resolving\n272: free\n273: resolving\n274: free\n275: valid\n276: resolving\n277: free\n278: resolving\n\n\n279: free\n280: valid\n281: free\n282: valid\n283: free\n284: resolving\n285: free\n286: valid\n\n\n287: resolving\n288: free\n289: resolving\n290: free\n291: resolving\n292: free\n293: resolving\n294: free\n295: resolving\n\n\n296: resolving\n297: free\n298: valid\n299: free\n300: resolving\n301: free\n302: valid\n303: free\n\n\n304: valid\n305: free\n306: valid\n307: free\n308: valid\n309: free\n310: valid\n311: free\n312: valid\n313: free\n\n\n314: valid\n315: free\n316: valid\n317: free\n318: valid\n319: free\n320: valid\n321: free\n322: valid\n323: free\n324: valid\n325: free\n326: valid\n327: free\n\n\n328: valid\n329: free\n330: valid\n331: free\n332: valid\n333: free\n334: valid\n335: free\n336: valid\n\n\n337: free\n338: valid\n339: free\n340: valid\n341: free\n342: valid\n343: free\n344: valid\n345: free\n346: valid\n347: free\n\n\n348: valid\n349: free\n350: valid\n351: free\n352: valid\n353: free\n354: resolving\n355: free\n356: valid\n357: free\n\n\n358: resolving\n359: free\n360: resolving\n361: free\n362: valid\n363: free\n364: valid\n365: free\n366: valid\n\n\n367: free\n368: valid\n369: free\n370: valid\n371: free\n372: valid\n373: free\n374: valid\n\n\n375: free\n376: valid\n377: resolving\n378: free\n379: resolving\n380: free\n381: valid\n382: free\n383: valid\n384: free\n385: valid\n386: free\n387: valid\n388: free\n389: valid\n\n\n390: free\n391: valid\n392: free\n393: valid\n394: free\n395: valid\n396: free\n397: valid\n398: free\n399: valid\n400: free\n401: valid\n\n\n402: free\n403: valid\n404: free\n405: valid\n406: free\n407: valid\n408: free\n409: valid\n410: free\n411: valid\n412: free\n413: valid\n414: free\n415: valid\n416: free\n\n\n417: valid\n418: free\n419: valid\n420: free\n421: valid\n422: free\n423: valid\n424: free\n425: valid\n426: free\n427: valid\n428: free\n429: valid\n\n\n430: free\n431: valid\n432: free\n433: valid\n434: free\n435: valid\n436: resolving\n437: valid\n438: free\n439: valid\n\n\n440: free\n441: valid\n442: free\n443: valid\n444: free\n445: valid\n446: free\n447: valid\n\n\n448: free\n449: valid\n450: free\n451: valid\n452: free\n453: valid\n454: free\n455: valid\n456: free\n457: valid\n458: free\n459: valid\n460: free\n461: valid\n\n\n462: free\n463: valid\n464: free\n465: valid\n466: free\n467: valid\n468: free\n469: valid\n\n\n470: free\n471: valid\n472: free\n473: valid\n474: free\n475: valid\n476: free\n477: valid\n478: free\n479: valid\n480: free\n481: valid\n482: free\n483: valid\n484: free\n485: valid\n\n\n486: free\n487: valid\n488: free\n489: valid\n490: free\n491: valid\n492: free\n493: valid\n494: free\n495: valid\n496: free\n\n\n497: valid\n498: free\n499: valid\n500: free\n501: valid\n502: free\n503: valid\n504: free\n505: valid\n\n\n506: free\n507: valid\n508: free\n509: valid\n510: free\n511: valid\n512: free\n513: valid\n514: free\n515: valid\n516: free\n517: valid\n518: free\n519: valid\n\n\n520: free\n521: valid\n522: free\n523: valid\n524: free\n525: valid\n526: free\n527: valid\n528: free\n529: valid\n530: free\n531: valid\n532: free\n533: valid\n\n\n534: valid\n535: free\n536: valid\n537: free\n538: valid\n539: free\n540: valid\n541: valid\n\n\n542: free\n543: valid\n544: free\n545: valid\n546: free\n547: valid\n548: free\n549: valid\n550: free\n551: valid\n552: free\n553: valid\n554: free\n555: valid\n\n\n556: free\n557: valid\n558: free\n559: valid\n560: free\n561: valid\n562: free\n563: valid\n564: free\n565: valid\n566: free\n\n\n567: valid\n568: free\n569: valid\n570: free\n571: valid\n572: free\n573: valid\n574: free\n575: valid\n576: free\n577: valid\n578: free\n579: valid\n580: free\n\n\n581: valid\n582: free\n583: valid\n584: free\n585: valid\n586: free\n587: valid\n588: free\n589: valid\n590: free\n591: valid\n592: valid\n593: free\n\n\n594: valid\n595: free\n596: valid\n597: free\n598: valid\n599: free\n600: valid\n601: free\n602: valid\n\n\n603: valid\n604: free\n605: valid\n606: free\n607: valid\n608: free\n609: valid\n610: free\n\n\n611: valid\n612: free\n613: valid\n614: free\n615: valid\n616: free\n617: valid\n618: free\n619: valid\n620: free\n621: valid\n622: free\n623: valid\n624: free\n625: valid\n626: free\n\n\n627: valid\n628: free\n629: valid\n630: free\n631: valid\n632: free\n633: valid\n634: free\n635: valid\n636: free\n637: valid\n638: free\n639: valid\n\n\n640: free\n641: valid\n642: free\n643: valid\n644: free\n645: valid\n646: free\n647: valid\n648: free\n\n\n649: valid\n650: free\n651: valid\n652: free\n653: valid\n654: valid\n655: free\n656: valid\n657: free\n658: valid\n659: valid\n660: free\n661: valid\n\n\n662: free\n663: valid\n664: valid\n665: free\n666: valid\n667: free\n668: valid\n669: valid\n670: valid\n671: free\n\n\n672: valid\n673: valid\n674: free\n675: valid\n676: free\n677: valid\n678: valid\n679: free\n680: valid\n681: valid\n682: free\n683: valid\n\n\n684: free\n685: valid\n686: free\n687: valid\n688: free\n689: valid\n690: valid\n691: free\n692: valid\n693: valid\n694: valid\n\n\n695: valid\n696: valid\n697: free\n698: valid\n699: valid\n700: free\n701: valid\n702: valid\n703: valid\n704: valid\n705: valid\n706: valid\n707: valid\n708: valid\n\n\n709: free\n710: valid\n711: valid\n712: valid\n713: valid\n714: valid\n715: valid\n716: free\n717: valid\nfinished\n\n\n<matplotlib.image.AxesImage at 0x7fb8f4c4d2e0>\n\n\n\n\n\n\nprint(f\"\"\"\n{time_update = }\n{time_select = }\n{time_dilate = }\n{time_existing = }\n{time_impossible = }\n{time_valid = }\n{time_possible = }\n{time_required = }\n{time_resolving = }\n{time_free = }\"\"\")\n\n\ntime_update = 7.823326199999992\ntime_select = 1.3680901999999975\ntime_dilate = 7.7121408999999925\ntime_existing = 1.8456800999999885\ntime_impossible = 1.442541699999989\ntime_valid = 0.01376379999998889\ntime_possible = 1.1864189999999741\ntime_required = 0.012239999999982487\ntime_resolving = 2.461927100000004\ntime_free = 0.8207929000000114"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inverse Design",
    "section": "",
    "text": "Trying to replicate the results of the following paper: - “Inverse design of photonic devices with strict foundry fabrication constraints”"
  }
]